{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('rapid': conda)",
      "metadata": {
        "interpreter": {
          "hash": "ba59d3597714fba378ce6785a785d823a533603ff6013eacaea4528cdbed07c9"
        }
      }
    },
    "colab": {
      "name": "mura_preprocessing.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN3JYaDfC2n_"
      },
      "source": [
        "### Download Mura Data \n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT24C2VCC2oB"
      },
      "source": [
        "mura_link = 'Enter Your Link Here'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UonnAinsC2oC"
      },
      "source": [
        "#### Upgrade Libraries if not upgraded in colab\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXCZMCWYC2oC"
      },
      "source": [
        "# !pip install --upgrade scikit-learn\n",
        "# !pip install --upgrade wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUtYrJBVC2oC"
      },
      "source": [
        "### Import libraries required for download\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rad4kDiC2oC"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from cv2 import imread, imshow\n",
        "from skimage.transform import rescale, resize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls397YHRC2oD"
      },
      "source": [
        "if os.path.exists('./mura_data'):\n",
        "    print(\"It exists no need to download\")\n",
        "else:\n",
        "    wget.download(mura_link,'./mura_zip')\n",
        "    with zipfile.ZipFile('mura_zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('./mura_data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCuHCYxLC2oD"
      },
      "source": [
        "### Validate paths and create the augmented pandas files\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzIQo1BIC2oD"
      },
      "source": [
        "ROOT_FOLDER = './mura_data/MURA-v1.1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyr7carxC2oE"
      },
      "source": [
        "BODY_PARTS = {\n",
        "'XR_ELBOW' : 0,\n",
        "'XR_FINGER' : 1,\n",
        "'XR_FOREARM': 2,\n",
        "'XR_HAND' : 3,\n",
        "'XR_HUMERUS': 4,\n",
        "'XR_SHOULDER': 5,\n",
        "'XR_WRIST': 6\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp4IthQEC2oE"
      },
      "source": [
        "def transform_pandas_file(mode):\n",
        "    _data = pd.read_csv(ROOT_FOLDER + f'/{mode}_image_paths.csv',header=None)\n",
        "    _data.columns = ['img_path']\n",
        "    def extract_label(x):\n",
        "        return  x.split('_')[-1].split('/')[0]\n",
        "  \n",
        "    def check_existence(x):\n",
        "        if os.path.exists(ROOT_FOLDER[:-9] + x):\n",
        "            return 'Exist'\n",
        "        else:\n",
        "            return 'Miss'\n",
        "\n",
        "    def extract_part(x):\n",
        "        return BODY_PARTS[x.split('/')[2]]\n",
        "  \n",
        "    _data['label'] = _data['img_path'].apply(lambda x: extract_label(x))\n",
        "    _data['valid'] = _data['img_path'].apply(lambda x: check_existence(x))\n",
        "    _data['part'] = _data['img_path'].apply(lambda x: extract_part(x))\n",
        "    _data.to_csv(ROOT_FOLDER + f'/{mode}_image_paths_aug.csv', index=False)\n",
        "    print(\"Saved file at: \" + ROOT_FOLDER + f'/{mode}_image_paths_aug.csv')\n",
        "    return\n",
        "\n",
        "\n",
        "transform_pandas_file('train')\n",
        "transform_pandas_file('valid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANu4ctTlC2oE"
      },
      "source": [
        "## Confirm that all exist so there is no need to validate them later\n",
        "new_train_df = pd.read_csv(ROOT_FOLDER + '/train_image_paths_aug.csv')\n",
        "assert (new_train_df['valid'] == 'Exist').all()\n",
        "\n",
        "new_valid_df = pd.read_csv(ROOT_FOLDER + '/valid_image_paths_aug.csv')\n",
        "assert (new_valid_df['valid'] == 'Exist').all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-kwrvreC2oF"
      },
      "source": [
        "### Convert all images to Grayscale\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dZClMY5C2oF"
      },
      "source": [
        "# GRAY_ROOT_FOLDER = './mura_data/MURA-v1.1-Gray'\n",
        "\n",
        "# def makedir(path):\n",
        "#     try:\n",
        "#         os.mkdir(path)\n",
        "#     except:\n",
        "#         return\n",
        "\n",
        "# def open_and_convert(src, name, dest):\n",
        "#     _x = imread(src + name)\n",
        "#     _x = cv2.cvtColor(_x, cv2.COLOR_BGR2GRAY)\n",
        "#     _f = dest+name\n",
        "#     makedir('/'.join(_f.split('/')[:-2]))\n",
        "#     makedir('/'.join(_f.split('/')[:-1]))\n",
        "#     cv2.imwrite(_f,  _x)\n",
        "#     return\n",
        "    \n",
        "# train_df = pd.read_csv(ROOT_FOLDER + '/train_image_paths_aug.csv')\n",
        "# val_df   = pd.read_csv(ROOT_FOLDER + '/valid_image_paths_aug.csv')\n",
        "\n",
        "# makedir(GRAY_ROOT_FOLDER)\n",
        "# makedir(GRAY_ROOT_FOLDER+'/train')\n",
        "# GRAY_ROOT_PREFIX = GRAY_ROOT_FOLDER+'/train'\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_ELBOW')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_FINGER')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_FOREARM')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_HAND')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_HUMERUS')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_SHOULDER')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_WRIST')\n",
        "\n",
        "# makedir(GRAY_ROOT_FOLDER+'/valid')\n",
        "# GRAY_ROOT_PREFIX = GRAY_ROOT_FOLDER+'/valid'\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_ELBOW')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_FINGER')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_FOREARM')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_HAND')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_HUMERUS')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_SHOULDER')\n",
        "# makedir(GRAY_ROOT_PREFIX+'/XR_WRIST')\n",
        "\n",
        "# train_image_paths = train_df['img_path'].values\n",
        "# train_labels = train_df['label'].values\n",
        "\n",
        "# val_image_paths = val_df['img_path'].values\n",
        "# val_labels = val_df['label'].values\n",
        "\n",
        "# src = ROOT_FOLDER + '/'\n",
        "# dest = GRAY_ROOT_FOLDER + '/'\n",
        "# for index, img_path in enumerate(train_image_paths):\n",
        "#     name = img_path[10:]\n",
        "#     open_and_convert(src,name,dest)\n",
        "#     if index % 1000 == 0 and index != 0:\n",
        "#         print(f\"{index} train images converted to grayscale...\")\n",
        "\n",
        "# for index, img_path in enumerate(val_image_paths):\n",
        "#     name = img_path[10:]\n",
        "#     open_and_convert(src,name,dest)\n",
        "#     if index % 1000 == 0 and index != 0:\n",
        "#         print(f\"{index} val images converted to grayscale...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqtDsZlAC2oG"
      },
      "source": [
        "### Delete the old images and rename the gray folder to the old one\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTz6Z8EqC2oG"
      },
      "source": [
        "# ### Move the files to the Gray Folder\n",
        "# !mv './mura_data/MURA-v1.1/*.csv' './mura_data/MURA-v1.1-Gray/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMWFbnPsC2oG"
      },
      "source": [
        "# !rm -rf './mura_data/MURA-v1.1'\n",
        "# !mv './mura_data/MURA-v1.1-Gray' './mura_data/MURA-v1.1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQxa8VpzC2oG"
      },
      "source": [
        "### Zoom in to discard edge information and resize to 224 by 224\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_eyKk8lC2oH"
      },
      "source": [
        "def resize_and_center_crop(name, dim=(224,224)):\n",
        "    _x = imread(name)\n",
        "    _x = cv2.resize(src=_x, dsize=(300,300), interpolation=cv2.INTER_LINEAR)\n",
        "    width, height = _x.shape[1], _x.shape[0]\n",
        "    crop_width = dim[0] if dim[0] < _x.shape[1] else _x.shape[1]\n",
        "    crop_height = dim[1] if dim[1] < _x.shape[0] else _x.shape[0] \n",
        "    mid_x, mid_y = int(width/2), int(height/2)\n",
        "    cw2, ch2     = int(crop_width/2), int(crop_height/2) \n",
        "    crop_img = _x[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]\n",
        "    cv2.imwrite(name,  crop_img)\n",
        "    return\n",
        "\n",
        "train_df = pd.read_csv(ROOT_FOLDER + '/train_image_paths_aug.csv')\n",
        "val_df   = pd.read_csv(ROOT_FOLDER + '/valid_image_paths_aug.csv')\n",
        "\n",
        "train_image_paths = train_df['img_path'].values\n",
        "val_image_paths = val_df['img_path'].values\n",
        "\n",
        "\n",
        "\n",
        "for index, img_path in enumerate(train_image_paths):\n",
        "    name = ROOT_FOLDER + '/' + img_path[10:]\n",
        "    resize_and_center_crop(name)\n",
        "    if index % 1000 == 0 and index != 0:\n",
        "        print(f\"{index} train images cropped...\")\n",
        "\n",
        "for index, img_path in enumerate(val_image_paths):\n",
        "    name = ROOT_FOLDER + '/' + img_path[10:]\n",
        "    resize_and_center_crop(name)\n",
        "    if index % 1000 == 0 and index != 0:\n",
        "        print(f\"{index} val images cropped...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NbdkN08C2oH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}